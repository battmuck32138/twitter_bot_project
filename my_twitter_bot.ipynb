{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MY Twitter-Bot Influencer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy \n",
    "from tweepy import TweepError \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 280)  #show at least 280 characters in columns, full tweets\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import string\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import Image, display\n",
    "from threading import Thread, Condition\n",
    "import time\n",
    "\n",
    "\n",
    "# twitter API credentials on seperate csv file\n",
    "file = open('new_keys.csv')\n",
    "reader = csv.reader(file)\n",
    "keys_list = list(reader)[0]\n",
    "consumer_key = keys_list[0]   \n",
    "consumer_secret = keys_list[1]\n",
    "access_key = keys_list[2]\n",
    "access_secret = keys_list[3]\n",
    "\n",
    "\n",
    "# authorize twitter, initialize tweepy\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    user_name = api.auth.get_username()\n",
    "    print(\"Developer credentials have been accepted.\")\n",
    "    \n",
    "except TweepError as e:\n",
    "    logging.warning(\"There was a Tweepy error. Double check your API keys and try again.\") \n",
    "    logging.warning(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to loop if scale exceeds 200 followers \n",
    "\n",
    "def follower_id_df(user_name):\n",
    "    \"\"\"parameter: twitter user_name\n",
    "       return: a dataframe object with a follower_id column\"\"\"\n",
    "    followers = api.followers(user_name, count=200)  #don't keep calling api\n",
    "    id_list = [follower.id for follower in followers]\n",
    "    return pd.DataFrame(id_list, columns=[\"follower_id\"])\n",
    "\n",
    "dataset_df = follower_id_df(user_name)\n",
    "dataset_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some tweets from my sheep\n",
    "\n",
    "def get_column_of_tweets(follower_id_ser, num_tweets):\n",
    "    \"\"\"follower_id_ser: is a series containing follower ids\n",
    "       num_tweets: is the number of tweets to grab per each user id \n",
    "       return: a list containing lists of num_tweets tweets for each follower_id\"\"\"\n",
    "    tweets_col = []\n",
    "    for id in follower_id_ser:\n",
    "        try:\n",
    "            tweets = [api.user_timeline(user_id=id, count=num_tweets)]\n",
    "        except tweepy.TweepError:\n",
    "            tweets = [tweets_col[0]]\n",
    "            print(\"Failed to run the command on that user, Skipping...\")\n",
    "        tweets_col += tweets\n",
    "    return tweets_col\n",
    "    \n",
    "    \n",
    "def tweets_to_text(tweets_list):\n",
    "    \"\"\"paramater: list containing x tweets\n",
    "       return: list containing the text portion of the tweets in tweets_list\"\"\"\n",
    "    return [tweet.text for tweet in tweets_list]\n",
    "    \n",
    "    \n",
    "\n",
    "#dataset_df[\"tweets\"] = get_column_of_tweets(dataset_df[\"follower_id\"], 20)\n",
    "#dataset_df[\"tweet_text\"] = dataset_df[\"tweets\"].apply(tweets_to_text)\n",
    "#dataset_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader Sentiment Analysis\n",
    "\n",
    "I built my sentiment analysis tool using the VADER lexicon (Valence Aware Dictionary for sEntiment Reasoning). \n",
    "\n",
    "The text file can be found here: %%html\n",
    "<a href=\"https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt\n",
    "\">\"VADER lexicon textfile\"</a>\n",
    "\n",
    "More info on VADER can be found here: %%html\n",
    "<a href=\"http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html\">\"VADER Tutorial\"</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darth_path = \"/Users/mathewbuck/Desktop/dighum100/twitter_bot/darth.jpg\"\n",
    "display(Image(darth_path, width=450, unconfined=True))\n",
    "\n",
    "vader_lex_df = pd.read_csv('vader_lexicon.txt', sep=\"\\t\", header=None) \n",
    "vader_lex_df.columns = ['word', 'polarity', 'junk', 'trash']\n",
    "vader_lex_df = vader_lex_df.drop(['junk', 'trash'], axis=1)\n",
    "#vader_lex_df.iloc[2000 : 2005]\n",
    "print(\"VADAR thinks that there are around 7,000 words that can help quantify the sentiment of a sentence.\")\n",
    "\n",
    "vader_lex_df.describe()\n",
    "extreme_neg = (vader_lex_df[vader_lex_df['polarity']\n",
    "                .agg(lambda x: (x <= -3.7))]\n",
    "                .sort_values('polarity')\n",
    "                .set_index(\"word\"))\n",
    "\n",
    "extreme_pos = (vader_lex_df[vader_lex_df['polarity']\n",
    "                .agg(lambda x: (x >= 3.3))]\n",
    "                .sort_values('polarity')\n",
    "                .set_index(\"word\"))\n",
    "\n",
    "fig = extreme_neg.plot.barh(figsize=(6, 3), color = \"red\")\n",
    "plt.xlim([-4, 4])\n",
    "plt.xlabel(\"POLARITY\")\n",
    "plt.ylabel(\"WORD\")\n",
    "plt.title(\"Words with Extreme Negative Sentiment\");\n",
    "print()\n",
    "\n",
    "fig = extreme_pos.plot.barh(figsize=(6, 3), color = \"blue\")\n",
    "plt.xlim([-4, 4])\n",
    "plt.xlabel(\"POLARITY\")\n",
    "plt.ylabel(\"WORD\")\n",
    "plt.title(\"Words with Extreme Positive Sentiment\");\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# methods ##################################################################################\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def sentiment_score(tweet_str):\n",
    "    \"\"\"parameter: string representing the text of a single tweet\n",
    "       return: the sentiment rating of sentence_str\"\"\"\n",
    "    return analyser.polarity_scores(tweet_str)[\"compound\"]\n",
    "    \n",
    "    \n",
    "def mean_sentiment(tweet_text_ser):\n",
    "    return pd.Series([sentiment_score(tweet_text) for tweet_text in tweet_text_ser]).mean()\n",
    "    \n",
    "#dataset_df[\"sentiment_score\"] = dataset_df[\"tweet_text\"].apply(mean_sentiment)\n",
    "#dataset_df = dataset_df[dataset_df['sentiment_score'].notnull()]\n",
    "#dataset_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell saves the DataFrame object I created above to text_df.csv in the project file.\n",
    "#dataset_df.to_csv(\"dataset_df.csv\", sep=',', encoding='utf-8', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell reads in the text_df.csv file I created earlier to speed up processing.\n",
    "dataset_df_path = \"/Users/mathewbuck/Desktop/dighum100/twitter_bot/dataset_df.csv\"\n",
    "dataset_df = pd.read_csv(dataset_df_path)\n",
    "dataset_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions / Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print()\n",
    "\n",
    "fig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.set(rc={\"figure.figsize\": (8, 4)}); np.random.seed(0)\n",
    "\n",
    "# Add a graph in each part\n",
    "fig = sns.boxplot(dataset_df[\"sentiment_score\"], ax=ax_box)\n",
    "plt.hist(dataset_df[\"sentiment_score\"], density=True, bins=25)  # `density=False` would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Sentiement Score');\n",
    "\n",
    "# Change figure size\n",
    "fig = sns.set(rc={'figure.figsize':(11.7, 8.27)}) \n",
    "\n",
    "# Move title up on y axis\n",
    "plt.title(\"Distribution of Sentiment Scores with Box Plot\", y=1.3, fontsize = 16);\n",
    "plt.show()\n",
    "\n",
    "dataset_df[\"sentiment_score\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Twitter Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "# TWITTER-BOT CODE #################################################################################################\n",
    "# DON'T RUN THE BOT MORE THAN ONCE A DAY TO AVOID SUSPENSIONS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "####################################################################################################################\n",
    "\n",
    "\n",
    "users_to_retweet = ([\"AndrewYang\",\"jimmy_dore\", \"JimmyDoreShow\", \"mtaibbi\", \"EricRWeinstein\", \"ZachandMattShow\", \n",
    "                     \"ucbyanggang\", \"RealCandaceO\", \"thrashermag\", \"joerogan\", \"DanCrenshawTX\", \"RepDanCrenshaw\", \n",
    "                     \"TulsiGabbard\", \"hilltvlive\", \"PagetKagy\", \"kthalps\", \"esaagar\", \"Timcast\", \"scrowder\", \n",
    "                     \"CHSommers\", \"SamHarrisOrg\"])\n",
    "\n",
    "\n",
    "def build_retweet_list(user_list, max_tweets_per_user):\n",
    "    \"\"\"user_list: list of user_names \n",
    "       max_tweets_per_user: maximum number of retweets that will be posted for any user_name\n",
    "       return: a list containing 1 or more tweet.id objects for each user_name in user_list \"\"\"\n",
    "    # make initial request for most recent tweets (20 is the maximum allowed count)\n",
    "    tweet_ids_list = []\n",
    "    for user in users_to_retweet:\n",
    "        tweets = api.user_timeline(id=user, count=random.randint(1, max_tweets_per_user))\n",
    "        tweet_ids = [tweet.id for tweet in tweets]\n",
    "        tweet_ids_list += tweet_ids\n",
    "\n",
    "    random.shuffle(tweet_ids_list)\n",
    "    print(\"Number of tweets that the bot will attempt to post: \", len(tweet_ids_list))\n",
    "    return tweet_ids_list\n",
    "\n",
    "\n",
    "def run_twitter_bot(users_to_retweet, max_tweets_per_user, min_seconds, max_seconds):\n",
    "    \"\"\"users_to_tetweet: list of twitter user_names associated with the users that the bot will retweet\n",
    "       max_tweets_per_user: maximum number of retweets that will be posted for any user_name\n",
    "       min_seconds: minimum time between tweets/follows\n",
    "       max_seconds: maximum time between tweets/follows\n",
    "       return: True upon completion\"\"\"\n",
    "    bot_path = \"/Users/mathewbuck/Desktop/dighum100/twitter_bot/twitter_bot.png\"\n",
    "    display(Image(bot_path, width=500, unconfined=True))\n",
    "    num_follows = 0\n",
    "    num_tweets_made = 0\n",
    "\n",
    "    for id in build_retweet_list(users_to_retweet, max_tweets_per_user):\n",
    "        first_100 = api.retweets(id, 100)  # get the first 100 retweets for each tweet \n",
    "    \n",
    "        # only retweet if post has already been retweeted at least 10 times \n",
    "        if len(first_100) > 10:\n",
    "        \n",
    "            try:\n",
    "                api.retweet(id)\n",
    "                num_tweets_made += 1\n",
    "                print()\n",
    "                print(\"Number of new tweets made: \", num_tweets_made)\n",
    "           \n",
    "            # catch 'You have already retweeted this Tweet.' errors \n",
    "            except tweepy.TweepError as e:\n",
    "                print()\n",
    "                print(e)\n",
    "            \n",
    "            #follow some peeps, some will follow back \n",
    "            potential_followers = first_100[4 : 8]  # only take 4 potential_followers per retweet\n",
    "            potential_screen_names = [sheep.user.screen_name for sheep in potential_followers]\n",
    "        \n",
    "            if len(potential_screen_names) > 0:\n",
    "                for screen_name in potential_screen_names:\n",
    "                    num_seconds = random.randint(min_seconds, max_seconds)  #adjust time period between re-tweets \n",
    "                    try:\n",
    "                        api.create_friendship(screen_name)  # follow some peeps \n",
    "                        num_follows += 1\n",
    "                        print(\"Number of new follows: \", num_follows)\n",
    "                        \n",
    "                    except tweepy.TweepError as e:\n",
    "                        print(e)\n",
    "                    \n",
    "                    print(\"Minutes until next follow: \", num_seconds / 60)\n",
    "                    time.sleep(num_seconds)\n",
    "                    \n",
    "    return True\n",
    "\n",
    "    \n",
    "# RUN THE TWITTER-BOT \n",
    "print(run_twitter_bot(users_to_retweet, max_tweets_per_user=1, min_seconds=27, max_seconds=133))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN TWO OR THREE TIMES A DAY OR TWITTER WILL SUSPEND ME AGAIN!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "def unfollow_users():\n",
    "    \"\"\"This method unfollows between 50 and 100 users.  \n",
    "    The number x and time intervals are chosen randomly to avoid creating detectable patterns.\n",
    "    return: True\"\"\"\n",
    "    x = random.randint(51, 101)\n",
    "    last_x_friends = api.friends(count=x)\n",
    "    last_x_screen_names = [sheep.screen_name for sheep in last_x_friends]\n",
    "    for sheep in last_x_screen_names:\n",
    "        try:\n",
    "            api.destroy_friendship(sheep)\n",
    "            num_seconds = random.randint(29, 121)  #adjust time period between re-tweets \n",
    "            time.sleep(num_seconds)\n",
    "        except tweepy.TweepError as e:\n",
    "            print(e)\n",
    "    print(\"Number of users that have been unfollowed: , x)\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
